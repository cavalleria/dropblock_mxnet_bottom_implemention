Namespace(batch_size=128, epochs=300, gpus='0,1,2,3', lamda=0.1, lr=0.01, lr_decay=0.1, lr_decay_epoch=[150, 225, inf], lr_mode='step', margin=0.1, momentum=0.9, mult=0.01, num_samples=-1, optimizer='nag', warmup_epochs=5, warmup_lr=0.0001, wd=0.0005, workers=8)
[Epoch 0] train=0.040029 val=0.104800 loss=752807.790894 time: 11.806434
[Epoch 1] train=0.075830 val=0.125100 loss=114472.000183 time: 10.852930
[Epoch 2] train=0.096247 val=0.128300 loss=114254.002197 time: 11.272311
[Epoch 3] train=0.117892 val=0.135600 loss=113882.634827 time: 10.945024
[Epoch 4] train=0.119241 val=0.137200 loss=113026.633636 time: 10.866939
[Epoch 5] train=0.117691 val=0.148800 loss=112307.433105 time: 10.895736
[Epoch 6] train=0.116080 val=0.153000 loss=111637.236237 time: 10.864803
[Epoch 7] train=0.147129 val=0.183400 loss=107975.971924 time: 10.856839
[Epoch 8] train=0.173506 val=0.214400 loss=106268.731995 time: 10.852809
[Epoch 9] train=0.183111 val=0.206200 loss=105482.016312 time: 10.939313
[Epoch 10] train=0.179708 val=0.204700 loss=104677.808411 time: 10.887240
[Epoch 11] train=0.192896 val=0.221800 loss=103141.249191 time: 10.814373
[Epoch 12] train=0.200588 val=0.230700 loss=102181.433792 time: 10.899963
[Epoch 13] train=0.201897 val=0.236200 loss=101659.791443 time: 10.864662
[Epoch 14] train=0.200487 val=0.231100 loss=101098.959702 time: 10.954700
[Epoch 15] train=0.194588 val=0.221600 loss=100840.702057 time: 10.886874
[Epoch 16] train=0.192534 val=0.220600 loss=100554.863800 time: 10.856382
[Epoch 17] train=0.196621 val=0.225100 loss=100335.119278 time: 10.983196
[Epoch 18] train=0.197245 val=0.244900 loss=100223.129501 time: 10.850539
[Epoch 19] train=0.193218 val=0.248300 loss=99987.219315 time: 10.870100
[Epoch 20] train=0.196360 val=0.259800 loss=99727.489471 time: 10.912732
[Epoch 21] train=0.194487 val=0.240900 loss=99603.923141 time: 10.963930
[Epoch 22] train=0.200890 val=0.240600 loss=99488.013153 time: 10.936984
[Epoch 23] train=0.198293 val=0.261700 loss=99274.424988 time: 10.797755
[Epoch 24] train=0.206689 val=0.261200 loss=99117.293686 time: 10.966126
[Epoch 25] train=0.221327 val=0.280400 loss=98602.225998 time: 10.817007
[Epoch 26] train=0.221066 val=0.280100 loss=98173.633957 time: 10.759569
[Epoch 27] train=0.225576 val=0.288700 loss=97948.639435 time: 10.799758
[Epoch 28] train=0.226341 val=0.280000 loss=97577.379974 time: 10.860275
[Epoch 29] train=0.233449 val=0.286600 loss=97181.420303 time: 11.236954
[Epoch 30] train=0.234838 val=0.290900 loss=96854.163315 time: 10.918231
[Epoch 31] train=0.241724 val=0.287500 loss=96667.836075 time: 10.901204
[Epoch 32] train=0.241281 val=0.286900 loss=96527.335297 time: 10.893548
[Epoch 33] train=0.243657 val=0.299900 loss=96353.994919 time: 10.874853
[Epoch 34] train=0.245550 val=0.293800 loss=95975.135300 time: 11.009354
[Epoch 35] train=0.249094 val=0.297600 loss=95652.930145 time: 10.860041
[Epoch 36] train=0.254289 val=0.306800 loss=95354.285904 time: 10.839836
[Epoch 37] train=0.254631 val=0.305900 loss=95107.096939 time: 10.874556
[Epoch 38] train=0.260933 val=0.323600 loss=94398.628342 time: 10.880502
[Epoch 39] train=0.265766 val=0.324200 loss=93958.552155 time: 10.862282
[Epoch 40] train=0.266451 val=0.340800 loss=93220.802628 time: 10.926012
[Epoch 41] train=0.274525 val=0.345700 loss=92828.905289 time: 10.869779
[Epoch 42] train=0.276981 val=0.337200 loss=92276.780090 time: 10.829710
[Epoch 43] train=0.280525 val=0.335000 loss=91698.696747 time: 10.901762
[Epoch 44] train=0.289304 val=0.347700 loss=91228.068680 time: 10.873740
[Epoch 45] train=0.291036 val=0.349400 loss=90976.816330 time: 10.965586
[Epoch 46] train=0.295606 val=0.343000 loss=90582.342941 time: 10.960146
[Epoch 47] train=0.296633 val=0.357500 loss=90395.823105 time: 10.828205
[Epoch 48] train=0.301707 val=0.373700 loss=89781.551788 time: 10.898014
[Epoch 49] train=0.301365 val=0.372800 loss=89718.417648 time: 10.887086
[Epoch 50] train=0.307567 val=0.364100 loss=89125.498047 time: 10.760719
[Epoch 51] train=0.308694 val=0.349400 loss=88858.951050 time: 10.927790
[Epoch 52] train=0.312319 val=0.355800 loss=88474.921082 time: 10.870972
[Epoch 53] train=0.315943 val=0.352400 loss=88383.215881 time: 11.025030
[Epoch 54] train=0.314393 val=0.371100 loss=88157.595078 time: 10.873769
[Epoch 55] train=0.317554 val=0.378600 loss=87909.569214 time: 10.818848
[Epoch 56] train=0.319527 val=0.383900 loss=87846.250397 time: 10.896487
[Epoch 57] train=0.318359 val=0.397000 loss=87273.208389 time: 10.771647
[Epoch 58] train=0.324319 val=0.392600 loss=87055.862000 time: 10.964822
[Epoch 59] train=0.321521 val=0.394100 loss=86998.440598 time: 10.877634
[Epoch 60] train=0.326454 val=0.378200 loss=86705.654282 time: 10.934092
[Epoch 61] train=0.327118 val=0.382900 loss=86313.265854 time: 10.905522
[Epoch 62] train=0.323897 val=0.368500 loss=86311.145462 time: 10.792354
[Epoch 63] train=0.329675 val=0.398200 loss=85784.448990 time: 10.811941
[Epoch 64] train=0.334105 val=0.416600 loss=85633.113297 time: 10.854960
[Epoch 65] train=0.335152 val=0.403000 loss=85248.490997 time: 10.864887
[Epoch 66] train=0.334830 val=0.404000 loss=84974.094803 time: 10.972393
[Epoch 67] train=0.337206 val=0.413700 loss=84700.693451 time: 10.807655
[Epoch 68] train=0.338958 val=0.414100 loss=84684.078339 time: 10.909916
[Epoch 69] train=0.340830 val=0.428700 loss=84270.323074 time: 10.892176
[Epoch 70] train=0.350697 val=0.413200 loss=83785.674805 time: 10.786716
[Epoch 71] train=0.355670 val=0.442500 loss=83379.927032 time: 10.816722
[Epoch 72] train=0.367711 val=0.440200 loss=82645.253372 time: 10.981908
[Epoch 73] train=0.385591 val=0.456400 loss=82050.113754 time: 10.901602
[Epoch 74] train=0.394451 val=0.462400 loss=81146.702805 time: 10.850497
[Epoch 75] train=0.405747 val=0.485200 loss=80431.394745 time: 10.820573
[Epoch 76] train=0.411606 val=0.477100 loss=79636.133118 time: 11.045997
[Epoch 77] train=0.418754 val=0.467500 loss=79063.827667 time: 10.952930
[Epoch 78] train=0.425217 val=0.509600 loss=78492.561218 time: 10.914816
[Epoch 79] train=0.429708 val=0.513600 loss=78219.243774 time: 10.900621
[Epoch 80] train=0.433976 val=0.539200 loss=77529.905212 time: 10.850936
[Epoch 81] train=0.439413 val=0.524000 loss=77177.854401 time: 10.747030
[Epoch 82] train=0.447709 val=0.537500 loss=76480.781494 time: 10.814336
[Epoch 83] train=0.450971 val=0.545000 loss=76075.858093 time: 10.865524
[Epoch 84] train=0.450870 val=0.511600 loss=75839.272980 time: 10.872586
[Epoch 85] train=0.456649 val=0.528000 loss=75312.195511 time: 10.804326
[Epoch 86] train=0.460374 val=0.539500 loss=74855.983887 time: 10.943540
[Epoch 87] train=0.465569 val=0.571800 loss=74463.280869 time: 10.766769
[Epoch 88] train=0.466575 val=0.559600 loss=74044.138550 time: 10.803336
[Epoch 89] train=0.467703 val=0.528700 loss=74313.195648 time: 10.874254
[Epoch 90] train=0.473663 val=0.496800 loss=73329.368393 time: 10.785633
[Epoch 91] train=0.477529 val=0.531500 loss=72961.868530 time: 10.898642
[Epoch 92] train=0.480912 val=0.560600 loss=72568.202240 time: 10.875881
[Epoch 93] train=0.486167 val=0.586200 loss=72042.415787 time: 10.822185
[Epoch 94] train=0.486630 val=0.593200 loss=71856.475479 time: 10.876666
[Epoch 95] train=0.491342 val=0.561500 loss=71516.341049 time: 10.847867
[Epoch 96] train=0.492147 val=0.600000 loss=71409.344055 time: 10.980582
[Epoch 97] train=0.496798 val=0.607200 loss=70540.771576 time: 10.960573
[Epoch 98] train=0.500101 val=0.578100 loss=70734.137421 time: 10.840293
[Epoch 99] train=0.509464 val=0.566200 loss=69794.536621 time: 10.924879
[Epoch 100] train=0.507853 val=0.586300 loss=69557.432953 time: 10.932317
[Epoch 101] train=0.512403 val=0.610900 loss=69382.991638 time: 10.879911
[Epoch 102] train=0.517457 val=0.597200 loss=68919.182281 time: 10.901388
[Epoch 103] train=0.520538 val=0.631900 loss=68276.503723 time: 10.741759
[Epoch 104] train=0.525834 val=0.615200 loss=67678.748322 time: 10.802927
[Epoch 105] train=0.524545 val=0.612200 loss=68027.481125 time: 10.964498
[Epoch 106] train=0.532317 val=0.622200 loss=67468.716919 time: 10.840679
[Epoch 107] train=0.535015 val=0.605300 loss=66873.604996 time: 10.905865
[Epoch 108] train=0.532035 val=0.607500 loss=67101.546097 time: 10.817025
[Epoch 109] train=0.539566 val=0.620400 loss=66567.572372 time: 10.897050
[Epoch 110] train=0.543835 val=0.643100 loss=65936.724655 time: 10.918297
[Epoch 111] train=0.545526 val=0.626400 loss=65463.620026 time: 11.047936
[Epoch 112] train=0.547378 val=0.655000 loss=65338.515549 time: 10.960310
[Epoch 113] train=0.548284 val=0.653400 loss=65475.880951 time: 10.812922
[Epoch 114] train=0.552956 val=0.641100 loss=64671.507416 time: 10.872343
[Epoch 115] train=0.550560 val=0.614300 loss=64608.569382 time: 10.831670
[Epoch 116] train=0.552795 val=0.677400 loss=64367.065979 time: 10.877081
[Epoch 117] train=0.556560 val=0.671900 loss=64040.469429 time: 10.854214
[Epoch 118] train=0.559842 val=0.657500 loss=63524.894127 time: 10.866873
[Epoch 119] train=0.564171 val=0.672500 loss=63776.711075 time: 10.869649
[Epoch 120] train=0.563789 val=0.654000 loss=63075.066101 time: 10.847254
[Epoch 121] train=0.568843 val=0.669600 loss=62738.954323 time: 10.793331
[Epoch 122] train=0.569708 val=0.679700 loss=62396.993057 time: 11.031357
[Epoch 123] train=0.570856 val=0.662200 loss=62263.980309 time: 10.854955
[Epoch 124] train=0.574682 val=0.691700 loss=61845.258301 time: 10.978174
[Epoch 125] train=0.577299 val=0.683800 loss=61555.270493 time: 10.947009
[Epoch 126] train=0.579595 val=0.687500 loss=61126.806763 time: 11.014306
[Epoch 127] train=0.578890 val=0.701600 loss=61538.099899 time: 10.874029
[Epoch 128] train=0.583723 val=0.678900 loss=60706.285065 time: 10.961844
[Epoch 129] train=0.588052 val=0.694900 loss=60444.745605 time: 10.855956
[Epoch 130] train=0.586582 val=0.664600 loss=60309.983116 time: 10.931095
[Epoch 131] train=0.587005 val=0.699300 loss=60313.844856 time: 10.918681
[Epoch 132] train=0.592522 val=0.706300 loss=59933.272026 time: 10.839736
[Epoch 133] train=0.597233 val=0.682100 loss=59164.779579 time: 10.964736
[Epoch 134] train=0.592743 val=0.695100 loss=59585.293594 time: 10.831028
[Epoch 135] train=0.598885 val=0.659900 loss=59102.875633 time: 10.896612
[Epoch 136] train=0.602670 val=0.693000 loss=58583.191124 time: 10.793177
[Epoch 137] train=0.601401 val=0.687500 loss=58838.956688 time: 10.901535
[Epoch 138] train=0.603959 val=0.707400 loss=58656.740669 time: 10.941741
[Epoch 139] train=0.609073 val=0.700500 loss=57943.026894 time: 10.877174
[Epoch 140] train=0.609033 val=0.713600 loss=57764.293709 time: 10.895853
[Epoch 141] train=0.612315 val=0.724400 loss=57532.711380 time: 10.938016
[Epoch 142] train=0.612295 val=0.723900 loss=57214.829086 time: 10.822951
[Epoch 143] train=0.615073 val=0.714000 loss=57057.809952 time: 10.800584
[Epoch 144] train=0.616946 val=0.723900 loss=56645.994049 time: 10.779900
[Epoch 145] train=0.617228 val=0.713600 loss=56970.522316 time: 10.813013
[Epoch 146] train=0.619503 val=0.727100 loss=56743.612656 time: 10.741473
[Epoch 147] train=0.624356 val=0.721000 loss=56161.890221 time: 10.833963
[Epoch 148] train=0.624054 val=0.661800 loss=55806.628380 time: 10.830372
[Epoch 149] train=0.624698 val=0.714700 loss=56197.618317 time: 10.977680
[Epoch 150] train=0.643363 val=0.764900 loss=53369.939171 time: 10.858237
[Epoch 151] train=0.644350 val=0.756300 loss=53009.032784 time: 10.888011
[Epoch 152] train=0.644491 val=0.768300 loss=53012.792328 time: 10.851981
[Epoch 153] train=0.646666 val=0.763800 loss=52618.395805 time: 10.854598
[Epoch 154] train=0.649021 val=0.768500 loss=52400.990387 time: 10.867262
[Epoch 155] train=0.648679 val=0.762000 loss=52725.626442 time: 10.940760
[Epoch 156] train=0.647974 val=0.764700 loss=52505.222366 time: 10.940717
[Epoch 157] train=0.648135 val=0.767100 loss=52510.182190 time: 10.892080
[Epoch 158] train=0.649082 val=0.758500 loss=52484.163017 time: 10.871836
[Epoch 159] train=0.654377 val=0.765100 loss=51677.376343 time: 10.865318
[Epoch 160] train=0.651357 val=0.770900 loss=51877.298820 time: 10.765171
[Epoch 161] train=0.653552 val=0.770600 loss=51866.982529 time: 10.873116
[Epoch 162] train=0.650773 val=0.761200 loss=52020.586411 time: 10.813096
[Epoch 163] train=0.653008 val=0.769400 loss=51681.728188 time: 10.850975
[Epoch 164] train=0.653028 val=0.768300 loss=52026.890144 time: 10.874774
[Epoch 165] train=0.654257 val=0.757300 loss=51748.113388 time: 10.907513
[Epoch 166] train=0.650693 val=0.770100 loss=52097.123718 time: 10.947563
[Epoch 167] train=0.653995 val=0.772500 loss=51754.678558 time: 10.854698
[Epoch 168] train=0.655183 val=0.767900 loss=51704.382401 time: 10.876460
[Epoch 169] train=0.655968 val=0.774100 loss=51660.603584 time: 10.912324
[Epoch 170] train=0.654337 val=0.767900 loss=51853.164078 time: 10.995959
[Epoch 171] train=0.654800 val=0.768100 loss=51641.587822 time: 10.781527
[Epoch 172] train=0.655525 val=0.769700 loss=51345.306602 time: 10.873687
[Epoch 173] train=0.655324 val=0.762900 loss=51815.734184 time: 10.911586
[Epoch 174] train=0.656290 val=0.769500 loss=51682.229530 time: 10.872290
[Epoch 175] train=0.654619 val=0.767600 loss=51784.499702 time: 10.925936
[Epoch 176] train=0.654518 val=0.767400 loss=52011.458344 time: 10.796000
[Epoch 177] train=0.658264 val=0.770300 loss=51169.326523 time: 10.806261
[Epoch 178] train=0.655364 val=0.770200 loss=51774.838707 time: 10.841495
[Epoch 179] train=0.658888 val=0.772600 loss=50893.554466 time: 10.829229
[Epoch 180] train=0.655565 val=0.772500 loss=51585.206635 time: 10.986419
[Epoch 181] train=0.657962 val=0.771200 loss=51323.214241 time: 10.775023
[Epoch 182] train=0.660660 val=0.765200 loss=51221.602837 time: 10.927540
[Epoch 183] train=0.660056 val=0.773000 loss=50825.024559 time: 10.913499
[Epoch 184] train=0.659472 val=0.765300 loss=51190.764343 time: 10.896029
[Epoch 185] train=0.660035 val=0.769400 loss=50907.440659 time: 10.835192
[Epoch 186] train=0.659633 val=0.767800 loss=50884.492203 time: 10.912226
[Epoch 187] train=0.659311 val=0.770800 loss=51179.110588 time: 10.763363
[Epoch 188] train=0.660156 val=0.772400 loss=51125.575043 time: 10.749058
[Epoch 189] train=0.659915 val=0.777500 loss=51038.296188 time: 10.833794
[Epoch 190] train=0.663076 val=0.760200 loss=50879.590157 time: 10.829119
[Epoch 191] train=0.660257 val=0.775100 loss=51040.406075 time: 10.974411
[Epoch 192] train=0.659170 val=0.764800 loss=50969.643768 time: 10.865198
[Epoch 193] train=0.661223 val=0.776800 loss=50739.701118 time: 10.819109
[Epoch 194] train=0.662351 val=0.775100 loss=50696.603378 time: 10.798666
[Epoch 195] train=0.666338 val=0.776500 loss=50424.580696 time: 10.837295
[Epoch 196] train=0.664747 val=0.778800 loss=50505.555511 time: 10.889060
[Epoch 197] train=0.662472 val=0.769500 loss=50662.643372 time: 11.000406
[Epoch 198] train=0.663479 val=0.775700 loss=50543.373001 time: 10.852885
[Epoch 199] train=0.662774 val=0.781600 loss=50766.014030 time: 10.918738
[Epoch 200] train=0.661143 val=0.775300 loss=50907.111343 time: 10.870641
[Epoch 201] train=0.665714 val=0.774000 loss=50459.874733 time: 10.894215
[Epoch 202] train=0.664022 val=0.775800 loss=50302.967072 time: 10.844445
[Epoch 203] train=0.663640 val=0.769100 loss=50498.887070 time: 10.685783
[Epoch 204] train=0.663559 val=0.773700 loss=50390.636513 time: 10.814540
[Epoch 205] train=0.667828 val=0.777900 loss=50277.564415 time: 10.924076
[Epoch 206] train=0.665331 val=0.775100 loss=50418.893997 time: 10.895769
[Epoch 207] train=0.665049 val=0.781000 loss=50296.692253 time: 10.927508
[Epoch 208] train=0.665009 val=0.774700 loss=50355.808502 time: 10.821162
[Epoch 209] train=0.664143 val=0.772600 loss=50699.844643 time: 10.816824
[Epoch 210] train=0.664485 val=0.774400 loss=50502.203087 time: 11.022899
[Epoch 211] train=0.666881 val=0.783400 loss=50100.246307 time: 10.924503
[Epoch 212] train=0.665049 val=0.776500 loss=50169.067162 time: 10.854898
[Epoch 213] train=0.665412 val=0.773200 loss=50254.360329 time: 11.081466
[Epoch 214] train=0.666740 val=0.780500 loss=49973.977135 time: 10.869864
[Epoch 215] train=0.666761 val=0.776900 loss=50164.667412 time: 10.812938
[Epoch 216] train=0.667183 val=0.781400 loss=50259.200546 time: 10.932998
[Epoch 217] train=0.662995 val=0.775700 loss=50314.882812 time: 10.891803
[Epoch 218] train=0.668110 val=0.772300 loss=50123.518044 time: 10.886896
[Epoch 219] train=0.669116 val=0.767500 loss=49845.123085 time: 10.792743
[Epoch 220] train=0.666499 val=0.782500 loss=49992.665222 time: 10.851663
[Epoch 221] train=0.669237 val=0.784300 loss=50006.826447 time: 10.936360
[Epoch 222] train=0.671895 val=0.774600 loss=49686.444664 time: 10.914464
[Epoch 223] train=0.670687 val=0.781900 loss=49783.327682 time: 10.866539
[Epoch 224] train=0.663962 val=0.777200 loss=50228.664803 time: 10.853826
[Epoch 225] train=0.670385 val=0.783100 loss=49263.478615 time: 10.885081
[Epoch 226] train=0.670345 val=0.783900 loss=49641.093529 time: 10.819515
[Epoch 227] train=0.674291 val=0.782900 loss=49151.068016 time: 10.872799
[Epoch 228] train=0.672419 val=0.783500 loss=49333.269920 time: 10.871059
[Epoch 229] train=0.671170 val=0.783100 loss=49533.760056 time: 10.933106
[Epoch 230] train=0.670264 val=0.782900 loss=49419.735367 time: 10.873518
[Epoch 231] train=0.672761 val=0.783400 loss=49214.213882 time: 10.951195
[Epoch 232] train=0.671211 val=0.783500 loss=49561.456276 time: 10.826981
[Epoch 233] train=0.672801 val=0.783500 loss=49153.053581 time: 10.849542
[Epoch 234] train=0.672076 val=0.784700 loss=49649.298126 time: 10.943636
[Epoch 235] train=0.672721 val=0.782700 loss=49443.303490 time: 10.970072
[Epoch 236] train=0.676124 val=0.784500 loss=49086.069839 time: 10.913142
[Epoch 237] train=0.673043 val=0.784200 loss=49051.522263 time: 10.725239
[Epoch 238] train=0.674352 val=0.783900 loss=49221.677780 time: 10.959495
[Epoch 239] train=0.672862 val=0.785600 loss=49115.078255 time: 10.971905
[Epoch 240] train=0.673546 val=0.785100 loss=49528.059105 time: 10.689834
[Epoch 241] train=0.672459 val=0.785000 loss=49168.374588 time: 10.935356
[Epoch 242] train=0.673204 val=0.784100 loss=49166.276367 time: 10.954628
[Epoch 243] train=0.670244 val=0.785800 loss=49583.424088 time: 10.878384
[Epoch 244] train=0.674815 val=0.785100 loss=49297.784843 time: 10.888918
[Epoch 245] train=0.671835 val=0.784400 loss=49303.116043 time: 10.753471
[Epoch 246] train=0.673284 val=0.783600 loss=49255.364189 time: 10.899096
[Epoch 247] train=0.672600 val=0.785400 loss=49119.545876 time: 11.052066
[Epoch 248] train=0.673103 val=0.784300 loss=49382.935356 time: 10.894406
[Epoch 249] train=0.673264 val=0.783700 loss=49125.902954 time: 10.880623
[Epoch 250] train=0.675157 val=0.783300 loss=48965.611664 time: 10.881444
[Epoch 251] train=0.671855 val=0.784400 loss=49479.627884 time: 10.812083
[Epoch 252] train=0.671150 val=0.784700 loss=49158.368988 time: 10.867723
[Epoch 253] train=0.671130 val=0.785000 loss=49422.057266 time: 11.057722
[Epoch 254] train=0.672258 val=0.783600 loss=49153.262566 time: 10.994623
[Epoch 255] train=0.676687 val=0.784400 loss=49068.208183 time: 10.820294
[Epoch 256] train=0.674613 val=0.785600 loss=49179.389999 time: 10.900598
[Epoch 257] train=0.672539 val=0.785800 loss=49184.455322 time: 10.833708
[Epoch 258] train=0.673828 val=0.787800 loss=49055.198578 time: 10.916006
[Epoch 259] train=0.674009 val=0.785900 loss=49004.574913 time: 10.857585
[Epoch 260] train=0.673627 val=0.785100 loss=49031.454796 time: 10.852967
[Epoch 261] train=0.669841 val=0.783000 loss=49153.709229 time: 10.807428
[Epoch 262] train=0.676285 val=0.785000 loss=48717.970055 time: 10.822347
[Epoch 263] train=0.673446 val=0.784500 loss=48963.639198 time: 10.918763
[Epoch 264] train=0.671090 val=0.785400 loss=49447.750771 time: 10.991827
[Epoch 265] train=0.670586 val=0.787300 loss=49251.297569 time: 10.869515
[Epoch 266] train=0.673808 val=0.784700 loss=49286.949318 time: 10.856861
[Epoch 267] train=0.672640 val=0.784900 loss=49092.118767 time: 10.904505
[Epoch 268] train=0.675298 val=0.785400 loss=49273.965660 time: 10.958647
[Epoch 269] train=0.672922 val=0.784300 loss=49165.466255 time: 10.869805
[Epoch 270] train=0.674251 val=0.785000 loss=49241.658470 time: 10.860516
[Epoch 271] train=0.673123 val=0.785400 loss=49197.445595 time: 10.809988
[Epoch 272] train=0.676204 val=0.785200 loss=48996.492249 time: 10.783736
[Epoch 273] train=0.673868 val=0.785700 loss=49256.702461 time: 10.959731
[Epoch 274] train=0.672519 val=0.786200 loss=49090.108223 time: 10.979579
[Epoch 275] train=0.675560 val=0.784800 loss=48840.476448 time: 10.757118
[Epoch 276] train=0.675801 val=0.784000 loss=48995.693047 time: 10.865738
[Epoch 277] train=0.671613 val=0.785300 loss=49447.897263 time: 10.900504
[Epoch 278] train=0.674009 val=0.786200 loss=48956.359505 time: 10.879152
[Epoch 279] train=0.673083 val=0.785800 loss=49186.986969 time: 10.834263
[Epoch 280] train=0.673365 val=0.785500 loss=49077.497795 time: 10.870659
[Epoch 281] train=0.674513 val=0.785400 loss=49041.946602 time: 10.884028
[Epoch 282] train=0.675862 val=0.785700 loss=49122.734657 time: 10.969115
[Epoch 283] train=0.673788 val=0.785800 loss=48915.911003 time: 10.791812
[Epoch 284] train=0.673587 val=0.785300 loss=48979.840263 time: 10.811819
[Epoch 285] train=0.673305 val=0.784600 loss=49113.251671 time: 10.869931
[Epoch 286] train=0.673043 val=0.786100 loss=49311.606148 time: 10.929237
[Epoch 287] train=0.673284 val=0.786500 loss=49076.518791 time: 10.857503
[Epoch 288] train=0.674895 val=0.786300 loss=49139.684494 time: 10.706066
[Epoch 289] train=0.672821 val=0.785400 loss=49264.024948 time: 10.928221
[Epoch 290] train=0.677674 val=0.784300 loss=48786.244568 time: 10.889395
[Epoch 291] train=0.672660 val=0.785800 loss=49166.568459 time: 10.797552
[Epoch 292] train=0.675781 val=0.785700 loss=49125.923225 time: 10.871202
[Epoch 293] train=0.675922 val=0.786200 loss=48768.162811 time: 10.908691
[Epoch 294] train=0.672499 val=0.786000 loss=49209.177071 time: 10.967856
[Epoch 295] train=0.679164 val=0.786000 loss=48497.702499 time: 10.756796
[Epoch 296] train=0.675983 val=0.787100 loss=48972.367256 time: 10.875669
[Epoch 297] train=0.674150 val=0.786500 loss=49021.805527 time: 10.798015
[Epoch 298] train=0.674311 val=0.785300 loss=49274.166283 time: 10.914222
[Epoch 299] train=0.672137 val=0.786700 loss=49315.068680 time: 10.901117
